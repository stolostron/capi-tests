package test

import (
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"testing"
	"time"
)

// TestDeployment_ApplyResources tests applying generated resources to the cluster
func TestDeployment_ApplyResources(t *testing.T) {

	config := NewTestConfig()
	outputDir := filepath.Join(config.RepoDir, config.GetOutputDirName())

	if !DirExists(outputDir) {
		PrintToTTY("‚ö†Ô∏è  Output directory does not exist: %s\n", outputDir)
		t.Skipf("Output directory does not exist: %s", outputDir)
	}

	PrintToTTY("\n=== Applying Kubernetes resources ===\n")

	// Get files to apply from centralized list (from 04_generate_yamls_test.go)
	expectedFiles := []string{
		"credentials.yaml",
		"is.yaml",
		"aro.yaml",
	}

	// Set kubectl context to Kind cluster
	context := fmt.Sprintf("kind-%s", config.ManagementClusterName)

	// Verify cluster is healthy before applying resources
	// This addresses connection issues after long controller startup periods (issue #265)
	if err := WaitForClusterHealthy(t, context, DefaultHealthCheckTimeout); err != nil {
		t.Fatalf("Cluster health check failed: %v", err)
	}

	for _, file := range expectedFiles {
		filePath := filepath.Join(outputDir, file)
		if !FileExists(filePath) {
			PrintToTTY("‚ùå Cannot apply missing file: %s\n", file)
			t.Errorf("Cannot apply missing file: %s", file)
			continue
		}

		PrintToTTY("Applying resource file: %s...\n", file)
		t.Logf("Applying resource file: %s", file)

		// Use ApplyWithRetry to handle transient connection issues
		if err := ApplyWithRetry(t, context, filePath, DefaultApplyMaxRetries); err != nil {
			PrintToTTY("‚ùå Failed to apply %s: %v\n", file, err)
			t.Errorf("Failed to apply %s: %v", file, err)
			continue
		}
	}

	PrintToTTY("\n=== Resource application complete ===\n\n")
}

// TestDeployment_ApplyCredentialsYAML tests applying credentials.yaml to the cluster
func TestDeployment_ApplyCredentialsYAML(t *testing.T) {
	file := "credentials.yaml"

	PrintToTTY("\n=== Applying %s ===\n", file)
	t.Logf("Applying %s", file)

	config := NewTestConfig()
	outputDir := filepath.Join(config.RepoDir, config.GetOutputDirName())

	if !DirExists(outputDir) {
		PrintToTTY("‚ö†Ô∏è  Output directory does not exist: %s\n\n", outputDir)
		t.Skipf("Output directory does not exist: %s", outputDir)
	}

	filePath := filepath.Join(outputDir, file)
	if !FileExists(filePath) {
		PrintToTTY("‚ùå %s not found at %s\n\n", file, filePath)
		t.Errorf("%s not found at %s.\n\n"+
			"This file should be generated by TestInfrastructure_GenerateResources.\n\n"+
			"To regenerate infrastructure files:\n"+
			"  go test -v ./test -run TestInfrastructure_GenerateResources",
			file, filePath)
		return
	}

	context := fmt.Sprintf("kind-%s", config.ManagementClusterName)

	// Verify cluster is healthy before applying resources
	// This addresses connection issues after long controller startup periods (issue #265)
	if err := WaitForClusterHealthy(t, context, DefaultHealthCheckTimeout); err != nil {
		t.Fatalf("Cluster health check failed: %v", err)
	}

	// Use ApplyWithRetry to handle transient connection issues
	if err := ApplyWithRetry(t, context, filePath, DefaultApplyMaxRetries); err != nil {
		PrintToTTY("‚ùå Failed to apply %s: %v\n\n", file, err)
		t.Errorf("Failed to apply %s: %v", file, err)
		return
	}

	PrintToTTY("‚úÖ Successfully applied %s\n\n", file)
}

// TestDeployment_ApplyInfrastructureSecretsYAML tests applying is.yaml to the cluster
func TestDeployment_ApplyInfrastructureSecretsYAML(t *testing.T) {
	file := "is.yaml"

	PrintToTTY("\n=== Applying %s (infrastructure secrets) ===\n", file)
	t.Logf("Applying %s (infrastructure secrets)", file)

	config := NewTestConfig()
	outputDir := filepath.Join(config.RepoDir, config.GetOutputDirName())

	if !DirExists(outputDir) {
		PrintToTTY("‚ö†Ô∏è  Output directory does not exist: %s\n\n", outputDir)
		t.Skipf("Output directory does not exist: %s", outputDir)
	}

	filePath := filepath.Join(outputDir, file)
	if !FileExists(filePath) {
		PrintToTTY("‚ùå %s not found at %s\n\n", file, filePath)
		t.Errorf("%s (infrastructure secrets) not found at %s.\n\n"+
			"This file should be generated by TestInfrastructure_GenerateResources.\n\n"+
			"To regenerate infrastructure files:\n"+
			"  go test -v ./test -run TestInfrastructure_GenerateResources",
			file, filePath)
		return
	}

	context := fmt.Sprintf("kind-%s", config.ManagementClusterName)

	// Verify cluster is healthy before applying resources
	// This addresses connection issues after long controller startup periods (issue #265)
	if err := WaitForClusterHealthy(t, context, DefaultHealthCheckTimeout); err != nil {
		t.Fatalf("Cluster health check failed: %v", err)
	}

	// Use ApplyWithRetry to handle transient connection issues
	if err := ApplyWithRetry(t, context, filePath, DefaultApplyMaxRetries); err != nil {
		PrintToTTY("‚ùå Failed to apply %s: %v\n\n", file, err)
		t.Errorf("Failed to apply %s: %v", file, err)
		return
	}

	PrintToTTY("‚úÖ Successfully applied %s\n\n", file)
}

// TestDeployment_ApplyAROClusterYAML tests applying aro.yaml to the cluster
func TestDeployment_ApplyAROClusterYAML(t *testing.T) {
	file := "aro.yaml"

	PrintToTTY("\n=== Applying %s (ARO cluster configuration) ===\n", file)
	t.Logf("Applying %s (ARO cluster configuration)", file)

	config := NewTestConfig()
	outputDir := filepath.Join(config.RepoDir, config.GetOutputDirName())

	if !DirExists(outputDir) {
		PrintToTTY("‚ö†Ô∏è  Output directory does not exist: %s\n\n", outputDir)
		t.Skipf("Output directory does not exist: %s", outputDir)
	}

	filePath := filepath.Join(outputDir, file)
	if !FileExists(filePath) {
		PrintToTTY("‚ùå %s not found at %s\n\n", file, filePath)
		t.Errorf("%s (ARO cluster configuration) not found at %s.\n\n"+
			"This file should be generated by TestInfrastructure_GenerateResources.\n\n"+
			"To regenerate infrastructure files:\n"+
			"  go test -v ./test -run TestInfrastructure_GenerateResources",
			file, filePath)
		return
	}

	context := fmt.Sprintf("kind-%s", config.ManagementClusterName)

	// Verify cluster is healthy before applying resources
	// This addresses connection issues after long controller startup periods (issue #265)
	if err := WaitForClusterHealthy(t, context, DefaultHealthCheckTimeout); err != nil {
		t.Fatalf("Cluster health check failed: %v", err)
	}

	// Use ApplyWithRetry to handle transient connection issues
	if err := ApplyWithRetry(t, context, filePath, DefaultApplyMaxRetries); err != nil {
		PrintToTTY("‚ùå Failed to apply %s: %v\n\n", file, err)
		t.Errorf("Failed to apply %s: %v", file, err)
		return
	}

	PrintToTTY("‚úÖ Successfully applied %s\n\n", file)
}

// TestDeployment_MonitorCluster tests monitoring the ARO cluster deployment
func TestDeployment_MonitorCluster(t *testing.T) {

	PrintToTTY("\n=== Starting Cluster Monitoring Test ===\n")

	config := NewTestConfig()

	PrintToTTY("Checking prerequisites...\n")
	if !DirExists(config.RepoDir) {
		PrintToTTY("‚ö†Ô∏è  Repository not cloned yet at %s\n", config.RepoDir)
		t.Skipf("Repository not cloned yet at %s", config.RepoDir)
	}
	PrintToTTY("‚úÖ Repository directory exists: %s\n", config.RepoDir)

	clusterctlPath := filepath.Join(config.RepoDir, config.ClusterctlBinPath)

	// If clusterctl binary doesn't exist, try to use system clusterctl
	PrintToTTY("Looking for clusterctl binary...\n")
	if !FileExists(clusterctlPath) {
		t.Logf("clusterctl binary not found at %s, checking system PATH", clusterctlPath)
		PrintToTTY("clusterctl binary not found at %s, checking system PATH...\n", clusterctlPath)
		if CommandExists("clusterctl") {
			clusterctlPath = "clusterctl"
			PrintToTTY("‚úÖ Using clusterctl from system PATH\n")
		} else {
			PrintToTTY("‚ùå clusterctl not found in system PATH\n")
			t.Skipf("clusterctl not found")
		}
	} else {
		PrintToTTY("‚úÖ Found clusterctl at: %s\n", clusterctlPath)
	}

	// Set kubectl context to Kind cluster
	context := fmt.Sprintf("kind-%s", config.ManagementClusterName)
	SetEnvVar(t, "KUBECONFIG", fmt.Sprintf("%s/.kube/config", os.Getenv("HOME")))

	// First, check if cluster resource exists
	// Use the provisioned cluster name from aro.yaml, not WORKLOAD_CLUSTER_NAME
	provisionedClusterName := config.GetProvisionedClusterName()
	PrintToTTY("\n=== Monitoring cluster deployment ===\n")
	PrintToTTY("Cluster: %s\n", provisionedClusterName)
	PrintToTTY("Namespace: %s\n", config.TestNamespace)
	PrintToTTY("Context: %s\n", context)
	PrintToTTY("\nChecking if cluster resource exists...\n")
	t.Logf("Checking for cluster resource: %s (namespace: %s)", provisionedClusterName, config.TestNamespace)

	output, err := RunCommand(t, "kubectl", "--context", context, "-n", config.TestNamespace, "get", "cluster", provisionedClusterName)
	if err != nil {
		PrintToTTY("‚ö†Ô∏è  Cluster resource not found (may not be deployed yet)\n\n")
		t.Skipf("Cluster resource not found (may not be deployed yet): %v", err)
	}

	PrintToTTY("‚úÖ Cluster resource exists\n")
	t.Logf("Cluster resource exists:\n%s", output)

	// Use clusterctl to describe the cluster
	PrintToTTY("\nüìä Fetching cluster status with clusterctl...\n")
	PrintToTTY("Running: %s describe cluster %s -n %s --show-conditions=all\n", clusterctlPath, provisionedClusterName, config.TestNamespace)
	PrintToTTY("This may take a few moments...\n")
	t.Logf("Monitoring cluster deployment status using clusterctl...")

	output, err = RunCommand(t, clusterctlPath, "describe", "cluster", provisionedClusterName, "-n", config.TestNamespace, "--show-conditions=all")
	if err != nil {
		PrintToTTY("\n‚ö†Ô∏è  clusterctl describe failed (cluster may still be initializing)\n")
		PrintToTTY("Error: %v\n\n", err)
		t.Logf("clusterctl describe failed (cluster may still be initializing): %v\nOutput: %s", err, output)
	} else {
		PrintToTTY("\n‚úÖ Successfully retrieved cluster status\n")
		PrintToTTY("\nCluster Status:\n%s\n\n", output)
		t.Logf("Cluster status:\n%s", output)
	}

	PrintToTTY("=== Cluster Monitoring Test Complete ===\n\n")
}

// TestDeployment_WaitForControlPlane waits for control plane to be ready
func TestDeployment_WaitForControlPlane(t *testing.T) {

	config := NewTestConfig()
	context := fmt.Sprintf("kind-%s", config.ManagementClusterName)

	// Get the specific AROControlPlane name for the cluster being deployed
	// This prevents checking the wrong control plane when multiple clusters exist (issue #355)
	provisionedClusterName := config.GetProvisionedClusterName()
	aroControlPlaneName := fmt.Sprintf("%s-control-plane", provisionedClusterName)

	// Wait for control plane to be ready (with configurable timeout)
	timeout := config.DeploymentTimeout
	pollInterval := 30 * time.Second
	startTime := time.Now()

	// Print to stderr for immediate visibility (unbuffered)
	PrintToTTY("\n=== Waiting for control plane to be ready ===\n")
	PrintToTTY("Cluster: %s\n", provisionedClusterName)
	PrintToTTY("AROControlPlane: %s\n", aroControlPlaneName)
	PrintToTTY("Namespace: %s\n", config.TestNamespace)
	PrintToTTY("Timeout: %v | Poll interval: %v\n\n", timeout, pollInterval)
	t.Logf("Waiting for control plane to be ready (namespace: %s, timeout: %v)...", config.TestNamespace, timeout)

	iteration := 0
	for {
		elapsed := time.Since(startTime)
		remaining := timeout - elapsed

		if elapsed > timeout {
			PrintToTTY("\n‚ùå Timeout reached after %v\n\n", elapsed.Round(time.Second))
			t.Errorf("Timeout waiting for control plane to be ready after %v.\n\n"+
				"Troubleshooting steps:\n"+
				"  1. Check AROControlPlane status: kubectl --context %s -n %s get arocontrolplane %s -o yaml\n"+
				"  2. Check cluster conditions: kubectl --context %s -n %s get cluster %s -o yaml\n"+
				"  3. Check controller logs: kubectl --context %s -n capz-system logs -l control-plane=controller-manager --tail=100\n"+
				"  4. Check Azure resource provisioning in Azure portal or:\n"+
				"     az resource list --resource-group %s-resgroup --output table\n\n"+
				"Common causes:\n"+
				"  - Azure resource provisioning taking longer than expected\n"+
				"  - Azure quota exceeded for the region\n"+
				"  - Network/DNS configuration issues\n"+
				"  - Invalid Azure credentials or permissions\n\n"+
				"To increase timeout: export DEPLOYMENT_TIMEOUT=60m",
				elapsed.Round(time.Second),
				context, config.TestNamespace, aroControlPlaneName,
				context, config.TestNamespace, provisionedClusterName,
				context,
				config.ClusterNamePrefix)
			return
		}

		iteration++

		// Print current check status
		PrintToTTY("[%d] Checking control plane status...\n", iteration)

		// ARO uses AROControlPlane, not kubeadmcontrolplane
		// Query the specific AROControlPlane for this cluster (issue #355)
		output, err := RunCommand(t, "kubectl", "--context", context, "get",
			"arocontrolplane", aroControlPlaneName, "-n", config.TestNamespace, "-o", "jsonpath={.status.ready}")

		// Print the result of the check
		if err != nil {
			PrintToTTY("[%d] ‚ö†Ô∏è  Status check failed: %v (output: %s)\n", iteration, err, output)
		} else {
			status := strings.TrimSpace(output)
			PrintToTTY("[%d] üìä Control plane ready status: %s\n", iteration, status)

			if status == "true" {
				PrintToTTY("\n‚úÖ Control plane is ready! (took %v)\n\n", elapsed.Round(time.Second))
				t.Log("Control plane is ready!")
				return
			}
		}

		// Fetch and display AROControlPlane conditions for better visibility
		// Query the specific AROControlPlane for this cluster (issue #355)
		conditionsOutput, condErr := RunCommandQuiet(t, "kubectl", "--context", context, "get",
			"arocontrolplane", aroControlPlaneName, "-n", config.TestNamespace, "-o", "jsonpath={.status.conditions}")
		if condErr == nil && strings.TrimSpace(conditionsOutput) != "" {
			PrintToTTY("[%d] üìã AROControlPlane conditions:\n", iteration)
			PrintToTTY("%s", FormatAROControlPlaneConditions(conditionsOutput))
		}

		// Report progress using helper function
		ReportProgress(t, iteration, elapsed, remaining, timeout)

		time.Sleep(pollInterval)
	}
}

// TestDeployment_CheckClusterConditions checks various cluster conditions
func TestDeployment_CheckClusterConditions(t *testing.T) {

	config := NewTestConfig()
	context := fmt.Sprintf("kind-%s", config.ManagementClusterName)

	// Use the provisioned cluster name from aro.yaml
	provisionedClusterName := config.GetProvisionedClusterName()

	PrintToTTY("\n=== Checking cluster conditions ===\n")
	PrintToTTY("Cluster: %s\n", provisionedClusterName)
	PrintToTTY("Namespace: %s\n\n", config.TestNamespace)
	t.Logf("Checking cluster conditions (namespace: %s)...", config.TestNamespace)

	// Check cluster status
	PrintToTTY("Fetching cluster status...\n")

	output, err := RunCommand(t, "kubectl", "--context", context, "-n", config.TestNamespace, "get", "cluster", provisionedClusterName, "-o", "yaml")
	if err != nil {
		PrintToTTY("‚ùå Failed to get cluster status: %v\n\n", err)
		t.Errorf("Failed to get cluster status: %v", err)
		return
	}

	// Log the cluster conditions
	if strings.Contains(output, "status:") {
		PrintToTTY("‚úÖ Cluster has status information\n")
		t.Log("Cluster has status information")
		// Extract conditions section
		if strings.Contains(output, "conditions:") {
			PrintToTTY("‚úÖ Cluster conditions are available\n\n")
			t.Log("Cluster conditions are available in the output")
		}
	}

	// Check for infrastructure ready condition
	PrintToTTY("Checking InfrastructureReady condition...\n")

	output, err = RunCommand(t, "kubectl", "--context", context, "-n", config.TestNamespace, "get", "cluster", provisionedClusterName,
		"-o", "jsonpath={.status.conditions[?(@.type=='InfrastructureReady')].status}")

	if err == nil && strings.TrimSpace(output) != "" {
		PrintToTTY("üìä InfrastructureReady status: %s\n", output)
		t.Logf("InfrastructureReady status: %s", output)
	}

	// Check for control plane ready condition
	PrintToTTY("Checking ControlPlaneReady condition...\n")

	output, err = RunCommand(t, "kubectl", "--context", context, "-n", config.TestNamespace, "get", "cluster", provisionedClusterName,
		"-o", "jsonpath={.status.conditions[?(@.type=='ControlPlaneReady')].status}")

	if err == nil && strings.TrimSpace(output) != "" {
		PrintToTTY("üìä ControlPlaneReady status: %s\n", output)
		t.Logf("ControlPlaneReady status: %s", output)
	}

	PrintToTTY("\n=== Cluster condition check complete ===\n\n")
}
